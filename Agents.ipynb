{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Human**s are excellent at **recognizing complex patterns**, \n",
    "- but they often rely on tools like books, Google Search, or calculators to supplement their knowledge. \n",
    "Similarly, **Generative AI models** can be trained to **use external tools to access real-time information** or **perform real-world actions**.\n",
    "\n",
    "For example, a model can access a database to get a customer's *purchase history* and generate *personalized recommendations*, or it can make API calls to send *emails* or complete *financial transactions*.\n",
    "\n",
    "To do this, the model **must not only** have **access to external tools**, but **must also be able to plan and execute tasks autonomously**. This combination of reasoning, logic, and access to external information creates the concept of an **\"agent,\"** which is a **program that extends the capabilities of a generative model**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are **AI agents**?\n",
    "A generative **AI agent** is an application that seeks to achieve a goal by **observing the world and interacting with it** through the tools at its disposal.\n",
    "\n",
    "**Agents are autonomous** and can act **without human intervention**, especially when they have well-defined goals.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Model, Tools, and Orchestration Layer in AI Agents\n",
    "### The Model \n",
    "\n",
    "In the context of an agent, the model refers to the **language model (LM)** that serves as the **agent's decision-making center**. It can be composed of one or more models of various sizes, **capable of following logics and reasoning frameworks such as ReAct, Chain-of-Thought or Tree-of-Thoughts**.\n",
    "\n",
    "### The Tools\n",
    "**Language models**, while powerful in generating text and images, **cannot interact directly with the outside world**. To overcome this limitation, tools allow agents to access external data and perform real actions.\n",
    "\n",
    "**The tools can have different levels of complexity** and **generally operate via web APIs** with **methods such as GET, POST, PATCH, and DELETE**. For example, an agent can use a tool to update a customer's information in a database or to obtain weather data to provide travel recommendations.\n",
    "\n",
    "With the tools, agents **can support advanced systems such as Retrieval-Augmented Generation (RAG)**, which expands the capabilities of the base model and allows it to work with up-to-date and specific information.\n",
    "\n",
    "<small>\"Retrieval-Augmented Generation (RAG) enhances generative AI models by integrating information retrieval. This allows large language models (LLMs) to respond to queries using both their training data and up-to-date information from external documents.\"</small>\n",
    "\n",
    "### The Orchestration Layer\n",
    "The **orchestration layer defines the cyclical process** by which the agent **acquires information, reasons, and makes decisions**. This cycle continues until the agent reaches a goal or checkpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agents vs. Models\n",
    "\n",
    "To understand the distinction between agents and models, consider the following table:\n",
    "\n",
    "| **Models** | **Agents** |\n",
    "|------------|-----------|\n",
    "| Knowledge is limited to what is available in their training data. | Knowledge is extended through the connection with external systems via tools. |\n",
    "| Single inference/prediction based on the user query. No management of session history or continuous context (e.g., chat history). | Managed session history (e.g., chat history) enables multi-turn inference and decision-making within the orchestration layer. A \"turn\" represents one user query and one agent response. |\n",
    "| No native tool implementation. | Tools are natively implemented in the agent architecture. |\n",
    "| No native logic layer implemented. Users must rely on structured prompts or reasoning frameworks (CoT, ReAct, etc.) to guide model predictions. | Native cognitive architecture integrates reasoning frameworks like CoT, ReAct, or pre-built agent frameworks like LangChain. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Cognitive Architectures: How AI Agents Operate**\n",
    "\n",
    "The idea behind the **cognitive architectures** of AI agents is similar to that of a **chef in a busy kitchen**. The chef's goal is to create delicious dishes through a cycle of **information gathering, planning, execution, and adaptation**.\n",
    "\n",
    "- **Information Gathering**: The chef checks customer orders and available ingredients.\n",
    "- **Reasoning**: Decides which dishes can be prepared.\n",
    "- **Action**: Starts cooking, adjusting quantities and preparation methods.\n",
    "- **Adaptation**: If an ingredient runs out or a customer provides feedback, the chef modifies the recipe in real-time.\n",
    "\n",
    "AI agents operate with a similar logic: **they process information, make decisions, and refine their actions based on the results obtained**. At the core of this architecture is the **orchestration layer**, which manages memory, state, reasoning, and planning. Orchestration is driven by **prompt engineering frameworks** that enhance the agent's interaction with the environment.\n",
    "\n",
    "---\n",
    "\n",
    "### **Reasoning Frameworks for AI Agents**\n",
    "Agents can use different **reasoning approaches**, including:\n",
    "\n",
    "1. **ReAct (Reason + Act)**\n",
    "   - A framework that allows agents to **reason before acting**, improving response consistency and reducing hallucinations.\n",
    "   - It has been shown to outperform many state-of-the-art AI solutions and increase user trust in LLMs.\n",
    "\n",
    "2. **Chain-of-Thought (CoT)**\n",
    "   - A technique that breaks down reasoning into **intermediate steps**, helping models perform complex tasks.\n",
    "   - Includes variants like **self-consistency, active-prompt, and multimodal CoT**, each with strengths and limitations.\n",
    "\n",
    "3. **Tree-of-Thought (ToT)**\n",
    "   - Generalizes the logic of **Chain-of-Thought**, allowing agents to **explore multiple reasoning paths** to solve strategic problems.\n",
    "\n",
    "---\n",
    "\n",
    "### **Example of an Agent with ReAct**\n",
    "When a user sends a request, an agent using the **ReAct** framework follows this process:\n",
    "\n",
    "1. **The user sends a query to the agent.**\n",
    "2. **The agent initiates the ReAct sequence:**\n",
    "   - **Thought**: What to do based on the query.\n",
    "   - **Action**: Decides on an action (e.g., search for flights, perform a web search, write code).\n",
    "   - **Tools**: Selects an appropriate tool, such as a flight API.\n",
    "   - **Observation**: Obtains the tool's results and updates its reasoning.\n",
    "3. **The Thought â†’ Action â†’ Observation cycle continues until an optimal response is obtained.**\n",
    "4. **The agent provides a final response to the user based on real data.**\n",
    "\n",
    "---\n",
    "\n",
    "### **Conclusion**\n",
    "The quality of agent responses depends on their **ability to reason and select the right tools**. Like a chef using fresh ingredients and listening to customer feedback, an AI agent must **rely on reliable information and a solid decision-making process** to deliver accurate and useful results.\n",
    "\n",
    "In the next section, the document delves into **how agents connect to up-to-date data to further improve their responses**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **ReAct** (Reasoning and Acting) framework is a prompting technique for large language models (LLMs) that combines reasoning with action to improve performance on complex tasks. Introduced by Yao et al. in 2022, ReAct allows models to generate both reasoning traces and task-specific actions in an interleaved manner, enabling greater synergy between the two. Reasoning traces help the model induce, track, and update action plans, as well as handle exceptions, while actions allow it to interface with external sources, such as knowledge bases or environments, to gather additional information.\n",
    "\n",
    "A typical ReAct prompt consists of a task description, few-shot examples showing the desired format, and alternating steps of \"Thought\", \"Action\", and \"Observation\". For example, for a complex question, the model might:\n",
    "\n",
    "1. **Thought**: Determine what information is needed.\n",
    "2. **Action**: Perform a search to obtain that information.\n",
    "3. **Observation**: Analyze the search results.\n",
    "4. **Thought**: Synthesize the gathered information.\n",
    "5. **Action**: Provide the final answer.\n",
    "\n",
    "This approach allows the model to dynamically update its knowledge and make more informed decisions, improving the accuracy and interpretability of responses. ReAct has been successfully applied to various tasks, including question answering, fact-checking, and decision-making in complex environments, outperforming methods based solely on reasoning or action."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tools: The Key to the External World**\n",
    "\n",
    "**Language models** are excellent at processing information, but **they cannot directly interact with the real world**. This limits their usefulness when interaction with external systems or up-to-date data is required.\n",
    "\n",
    "To overcome this limitation, there are various tools that connect the AI model with the external world, including:\n",
    "- **Functions**\n",
    "- **Extensions**\n",
    "- **Data Stores**\n",
    "- **Plugins**\n",
    "\n",
    "These tools allow agents to perform **real-time actions**, such as:\n",
    "- Adjusting smart home settings\n",
    "- Updating calendars\n",
    "- Retrieving information from a database\n",
    "- Sending emails\n",
    "\n",
    "Currently, Google's models interact with **three main types of tools**:\n",
    "1. **Extensions**\n",
    "2. **Functions**\n",
    "3. **Data Stores**\n",
    "\n",
    "---\n",
    "\n",
    "### **Extensions**\n",
    "**Extensions** are the bridge between an **AI agent and an API**, standardizing API calls to make them more flexible and scalable.\n",
    "\n",
    "#### **Practical Example: Flight Booking**\n",
    "- A user asks: *\"I want to book a flight from Austin to Zurich.\"*\n",
    "- The agent needs to parse the text and call the **Google Flights** API.\n",
    "- If the user **does not provide the departure city**, the API would fail due to missing essential data.\n",
    "\n",
    "A **rigid approach** with custom code might fail in such cases, requiring continuous updates to handle exceptions. **Extensions solve this problem** by teaching the agent:\n",
    "- **How to use the API** with practical examples\n",
    "- **Which parameters** are necessary for API calls\n",
    "\n",
    "---\n",
    "\n",
    "### **Advantages of Extensions**\n",
    "- **More robust and flexible than custom code**\n",
    "- **Independent of the agent**, can be integrated dynamically\n",
    "- **Allow selecting the most suitable extension based on the user's request**\n",
    "- **Google provides preconfigured Extensions** to simplify integration, such as a **Code Interpreter** to execute Python code from a textual description\n",
    "\n",
    "---\n",
    "\n",
    "### **Conclusion**\n",
    "Tools like **Extensions** enable AI agents to **interact with the real world**, enhancing their usefulness and accuracy. Thanks to these tools, an AI agent can **dynamically choose the best method to solve a request**, just as a software developer would select an appropriate API for a problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Import the Necessary Libraries\n",
    "First, let's import the required libraries:\n",
    "\n",
    "- `vertexai` to interact with Google's Vertex AI.\n",
    "- `pprint` to print the results in a readable format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: vertexai in c:\\users\\dell\\anaconda3\\envs\\my_env\\lib\\site-packages (1.71.1)\n",
      "Requirement already satisfied: google-cloud-aiplatform==1.71.1 in c:\\users\\dell\\anaconda3\\envs\\my_env\\lib\\site-packages (from google-cloud-aiplatform[all]==1.71.1->vertexai) (1.71.1)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in c:\\users\\dell\\anaconda3\\envs\\my_env\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (2.24.1)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in c:\\users\\dell\\anaconda3\\envs\\my_env\\lib\\site-packages (from google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (2.38.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\dell\\anaconda3\\envs\\my_env\\lib\\site-packages (from google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (1.26.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 in c:\\users\\dell\\anaconda3\\envs\\my_env\\lib\\site-packages (from google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (5.28.3)\n",
      "Requirement already satisfied: packaging>=14.3 in c:\\users\\dell\\anaconda3\\envs\\my_env\\lib\\site-packages (from google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (24.2)\n",
      "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in c:\\users\\dell\\anaconda3\\envs\\my_env\\lib\\site-packages (from google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (2.19.0)\n",
      "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in c:\\users\\dell\\anaconda3\\envs\\my_env\\lib\\site-packages (from google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (3.29.0)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in c:\\users\\dell\\anaconda3\\envs\\my_env\\lib\\site-packages (from google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (1.14.0)\n",
      "Requirement already satisfied: shapely<3.0.0dev in c:\\users\\dell\\anaconda3\\envs\\my_env\\lib\\site-packages (from google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (2.0.7)\n",
      "Requirement already satisfied: pydantic<3 in c:\\users\\dell\\anaconda3\\envs\\my_env\\lib\\site-packages (from google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (2.10.6)\n",
      "Requirement already satisfied: docstring-parser<1 in c:\\users\\dell\\anaconda3\\envs\\my_env\\lib\\site-packages (from google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (0.16)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\dell\\anaconda3\\envs\\my_env\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (1.67.0rc1)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in c:\\users\\dell\\anaconda3\\envs\\my_env\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (2.32.3)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\dell\\anaconda3\\envs\\my_env\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (1.70.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in c:\\users\\dell\\anaconda3\\envs\\my_env\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (1.70.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\dell\\anaconda3\\envs\\my_env\\lib\\site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (5.5.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\dell\\anaconda3\\envs\\my_env\\lib\\site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\dell\\anaconda3\\envs\\my_env\\lib\\site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (4.9)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=2.4.1 in c:\\users\\dell\\anaconda3\\envs\\my_env\\lib\\site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (2.4.1)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=2.0.0 in c:\\users\\dell\\anaconda3\\envs\\my_env\\lib\\site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (2.7.2)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.3 in c:\\users\\dell\\anaconda3\\envs\\my_env\\lib\\site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (2.9.0.post0)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in c:\\users\\dell\\anaconda3\\envs\\my_env\\lib\\site-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (0.14.0)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in c:\\users\\dell\\anaconda3\\envs\\my_env\\lib\\site-packages (from google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (1.6.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\dell\\anaconda3\\envs\\my_env\\lib\\site-packages (from pydantic<3->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\dell\\anaconda3\\envs\\my_env\\lib\\site-packages (from pydantic<3->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (2.27.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\dell\\anaconda3\\envs\\my_env\\lib\\site-packages (from pydantic<3->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (4.12.2)\n",
      "Requirement already satisfied: numpy<3,>=1.14 in c:\\users\\dell\\anaconda3\\envs\\my_env\\lib\\site-packages (from shapely<3.0.0dev->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (1.26.4)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\dell\\anaconda3\\envs\\my_env\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (0.6.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dell\\anaconda3\\envs\\my_env\\lib\\site-packages (from python-dateutil<3.0dev,>=2.7.3->google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\dell\\anaconda3\\envs\\my_env\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\anaconda3\\envs\\my_env\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dell\\anaconda3\\envs\\my_env\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\anaconda3\\envs\\my_env\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (2024.12.14)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: google-cloud-aiplatform 1.71.1 does not provide the extra 'all'\n"
     ]
    }
   ],
   "source": [
    "%pip install vertexai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.71.1\n"
     ]
    }
   ],
   "source": [
    "import vertexai # the library that allows us to use Google's Vertex AI to make requests to AI models.\n",
    "import pprint # It helps to format the text in output, making it more readable.\n",
    "\n",
    "print(vertexai.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = \"YOUR_PROJECT_ID\"  # Replace with your actual Project ID\n",
    "REGION = \"us-central1\"  # Region where Vertex AI is active\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=REGION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "DefaultCredentialsError",
     "evalue": "Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDefaultCredentialsError\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Import and Load the Code Interpreter Extension\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mvertexai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreview\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mextensions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Extension\n\u001b[1;32m----> 4\u001b[0m extension_code_interpreter \u001b[38;5;241m=\u001b[39m \u001b[43mExtension\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_hub\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcode_interpreter\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Extension.from_hub(\"code_interpreter\") loads the Code Interpreter extension, which allows the AI agent to dynamically write and execute Python code.\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# This extension enables generating code on demand and executing it.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\DELL\\anaconda3\\envs\\my_env\\Lib\\site-packages\\vertexai\\extensions\\_extensions.py:342\u001b[0m, in \u001b[0;36mExtension.from_hub\u001b[1;34m(cls, name, runtime_config)\u001b[0m\n\u001b[0;32m    340\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported 1P extension name: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    341\u001b[0m extension_info \u001b[38;5;241m=\u001b[39m _VERTEX_EXTENSION_HUB[name]\n\u001b[1;32m--> 342\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdisplay_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextension_info\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdisplay_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextension_info\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdescription\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmanifest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextension_info\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmanifest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mruntime_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mruntime_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\DELL\\anaconda3\\envs\\my_env\\Lib\\site-packages\\vertexai\\extensions\\_extensions.py:156\u001b[0m, in \u001b[0;36mExtension.create\u001b[1;34m(cls, manifest, extension_name, display_name, description, runtime_config)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Creates a new Extension.\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \n\u001b[0;32m    131\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;124;03m    Extension: The extension that was created.\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    155\u001b[0m sdk_resource \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m)\n\u001b[1;32m--> 156\u001b[0m \u001b[43mbase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mVertexAiResourceNounWithFutureManager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m    \u001b[49m\u001b[43msdk_resource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresource_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextension_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    160\u001b[0m extension \u001b[38;5;241m=\u001b[39m types\u001b[38;5;241m.\u001b[39mExtension(\n\u001b[0;32m    161\u001b[0m     name\u001b[38;5;241m=\u001b[39mextension_name,\n\u001b[0;32m    162\u001b[0m     display_name\u001b[38;5;241m=\u001b[39mdisplay_name \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_display_name(),\n\u001b[0;32m    163\u001b[0m     description\u001b[38;5;241m=\u001b[39mdescription,\n\u001b[0;32m    164\u001b[0m     manifest\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mto_proto(manifest, types\u001b[38;5;241m.\u001b[39mExtensionManifest()),\n\u001b[0;32m    165\u001b[0m )\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m runtime_config:\n",
      "File \u001b[1;32mc:\\Users\\DELL\\anaconda3\\envs\\my_env\\Lib\\site-packages\\google\\cloud\\aiplatform\\base.py:1234\u001b[0m, in \u001b[0;36mVertexAiResourceNounWithFutureManager.__init__\u001b[1;34m(self, project, location, credentials, resource_name)\u001b[0m\n\u001b[0;32m   1217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m   1218\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1219\u001b[0m     project: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     resource_name: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1223\u001b[0m ):\n\u001b[0;32m   1224\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Initializes class with project, location, and api_client.\u001b[39;00m\n\u001b[0;32m   1225\u001b[0m \n\u001b[0;32m   1226\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1232\u001b[0m \u001b[38;5;124;03m        resource_name(str): A fully-qualified resource name or ID.\u001b[39;00m\n\u001b[0;32m   1233\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1234\u001b[0m     \u001b[43m_VertexAiResourceNounPlus\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1235\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1236\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproject\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1239\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresource_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresource_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1240\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1241\u001b[0m     FutureManager\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\DELL\\anaconda3\\envs\\my_env\\Lib\\site-packages\\google\\cloud\\aiplatform\\base.py:558\u001b[0m, in \u001b[0;36mVertexAiResourceNoun.__init__\u001b[1;34m(self, project, location, credentials, resource_name)\u001b[0m\n\u001b[0;32m    556\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproject \u001b[38;5;241m=\u001b[39m project \u001b[38;5;129;01mor\u001b[39;00m initializer\u001b[38;5;241m.\u001b[39mglobal_config\u001b[38;5;241m.\u001b[39mproject\n\u001b[0;32m    557\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlocation \u001b[38;5;241m=\u001b[39m location \u001b[38;5;129;01mor\u001b[39;00m initializer\u001b[38;5;241m.\u001b[39mglobal_config\u001b[38;5;241m.\u001b[39mlocation\n\u001b[1;32m--> 558\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcredentials \u001b[38;5;241m=\u001b[39m credentials \u001b[38;5;129;01mor\u001b[39;00m \u001b[43minitializer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglobal_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcredentials\u001b[49m\n\u001b[0;32m    560\u001b[0m appended_user_agent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m base_constants\u001b[38;5;241m.\u001b[39mUSER_AGENT_SDK_COMMAND:\n",
      "File \u001b[1;32mc:\\Users\\DELL\\anaconda3\\envs\\my_env\\Lib\\site-packages\\google\\cloud\\aiplatform\\initializer.py:392\u001b[0m, in \u001b[0;36m_Config.credentials\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    390\u001b[0m logging_warning_filter \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mLoggingFilter(logging\u001b[38;5;241m.\u001b[39mWARNING)\n\u001b[0;32m    391\u001b[0m logger\u001b[38;5;241m.\u001b[39maddFilter(logging_warning_filter)\n\u001b[1;32m--> 392\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_project_as_env_var_or_google_auth_default\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    393\u001b[0m credentials \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_credentials\n\u001b[0;32m    394\u001b[0m logger\u001b[38;5;241m.\u001b[39mremoveFilter(logging_warning_filter)\n",
      "File \u001b[1;32mc:\\Users\\DELL\\anaconda3\\envs\\my_env\\Lib\\site-packages\\google\\cloud\\aiplatform\\initializer.py:117\u001b[0m, in \u001b[0;36m_Config._set_project_as_env_var_or_google_auth_default\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_project \u001b[38;5;241m=\u001b[39m project\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_credentials \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_api_key:\n\u001b[1;32m--> 117\u001b[0m     credentials, _ \u001b[38;5;241m=\u001b[39m \u001b[43mgoogle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefault\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_credentials \u001b[38;5;241m=\u001b[39m credentials\n",
      "File \u001b[1;32mc:\\Users\\DELL\\anaconda3\\envs\\my_env\\Lib\\site-packages\\google\\auth\\_default.py:719\u001b[0m, in \u001b[0;36mdefault\u001b[1;34m(scopes, request, quota_project_id, default_scopes)\u001b[0m\n\u001b[0;32m    711\u001b[0m             _LOGGER\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m    712\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo project ID could be determined. Consider running \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    713\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`gcloud config set project` or setting the \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    714\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menvironment variable\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    715\u001b[0m                 environment_vars\u001b[38;5;241m.\u001b[39mPROJECT,\n\u001b[0;32m    716\u001b[0m             )\n\u001b[0;32m    717\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m credentials, effective_project_id\n\u001b[1;32m--> 719\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mDefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)\n",
      "\u001b[1;31mDefaultCredentialsError\u001b[0m: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information."
     ]
    }
   ],
   "source": [
    "# Import and Load the Code Interpreter Extension\n",
    "from vertexai.preview.extensions import Extension\n",
    "\n",
    "extension_code_interpreter = Extension.from_hub(\"code_interpreter\")\n",
    "\n",
    "# Extension.from_hub(\"code_interpreter\") loads the Code Interpreter extension, which allows the AI agent to dynamically write and execute Python code.\n",
    "# This extension enables generating code on demand and executing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Request to Generate Code\n",
    "CODE_QUERY = \"\"\"Write a python method to invert a binary tree in O(n) time.\"\"\"\n",
    "\n",
    "# The CODE_QUERY variable contains the question we are sending to the AI agent.\n",
    "# In this case, we are asking to generate an algorithm to invert a binary tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the Request with the Code Interpreter\n",
    "response = extension_code_interpreter.execute(\n",
    "    operation_id=\"generate_and_execute\",\n",
    "    operation_params={\"query\": CODE_QUERY}\n",
    ")\n",
    "\n",
    "print(\"Generated Code:\")\n",
    "pprint.pprint({response['generated_code']})\n",
    "\n",
    "# execute() sends the request to the agent to generate and execute the code.\n",
    "# operation_id=\"generate_and_execute\" indicates that we want to both generate and execute the code.\n",
    "# operation_params={\"query\": CODE_QUERY} passes the question to the function so that the agent generates the desired code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Functions: Modular Tools for AI Agents**\n",
    "\n",
    "In the world of software development, **functions** are self-contained code modules that perform specific tasks and can be reused. A developer defines:\n",
    "- **Which function to use** (e.g., `function_a` or `function_b`).\n",
    "- **Which parameters to provide** and **what results to expect**.\n",
    "\n",
    "In **AI agents**, functions work similarly, with the difference that the **choice of function and arguments is managed by the model** itself, rather than by a human developer.\n",
    "\n",
    "---\n",
    "\n",
    "### **Differences Between Functions and Extensions**\n",
    "1. **Functions do not directly execute API calls**\n",
    "   - The model generates a function with parameters but does not directly execute it on an external API.\n",
    "   - APIs are called from the **client-side** (e.g., an external application), not by the AI agent.\n",
    "\n",
    "2. **Functions are executed client-side, while extensions are agent-side**\n",
    "   - **Extensions** are integrated into the agent's architecture and directly interact with external APIs.\n",
    "   - **Functions** are executed by **client-side software**, giving the programmer more control over the interaction with APIs.\n",
    "\n",
    "---\n",
    "\n",
    "### **Example: Flight Booking with Functions vs. Extensions**\n",
    "- With an **Extension**, the agent directly calls the **Google Flights API** and returns the results to the user.\n",
    "- With a **Function**, the agent decides which function to use, but the API call is handled **elsewhere**, such as in the **client backend or middleware**.\n",
    "\n",
    "ðŸ“Œ **Why use Functions instead of Extensions?**\n",
    "- **If the API call needs to occur at another level** of the application (e.g., frontend, middleware).\n",
    "- **For security or authentication reasons**, if the API is not directly accessible by the agent.\n",
    "- **For batch operations or human review**, where APIs need to be called in a specific order.\n",
    "- **To transform data before passing it to the agent**, if the API does not offer filtering tools.\n",
    "- **To develop and test agents without modifying existing APIs** (e.g., simulating API calls).\n",
    "\n",
    "---\n",
    "\n",
    "### **Conclusion**\n",
    "**Functions** give developers more control, separating the AI agent's logic from the API infrastructure, while **Extensions** allow for more direct and automated integration. The choice depends on the **security constraints, data flow, and customization needs** of the application.\n",
    "In summary, **AI agents operate similarly to a programming script** but with an additional level of intelligence and automation. **They autonomously decide which functions to use and how to execute them**, allowing them to respond effectively and dynamically to user requests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data Stores: The Solution for Dynamic Data in AI Agents**\n",
    "\n",
    "**Language models** are like a **large library** containing everything learned during training. However, **they cannot automatically update with new information**, which is a limitation when real-world knowledge changes.\n",
    "\n",
    "**Data Stores solve this problem** by providing access to **real-time updated data**, keeping the model's responses **more accurate and relevant**.\n",
    "\n",
    "---\n",
    "\n",
    "### **How Do Data Stores Work?**\n",
    "Imagine a **developer** needing to provide additional data to an AI agent, such as an **Excel sheet, a PDF, or a structured database**.\n",
    "\n",
    "**With Data Stores**, the agent can directly access this data without needing to:\n",
    "- **Manually convert data formats**\n",
    "- **Retrain the model**\n",
    "- **Perform fine-tuning**\n",
    "\n",
    "**How does the integration work?**\n",
    "1. The **Data Store** converts the document into **vector embeddings** (a mathematical representation of the data).\n",
    "2. The agent uses these embeddings to **extract useful information** when needed.\n",
    "3. The model can then **combine the Data Store's data with its pre-trained knowledge** to generate more accurate responses.\n",
    "\n",
    "---\n",
    "\n",
    "### **Applications of Data Stores**\n",
    "**Data Stores** are often implemented as **vector databases**, allowing the agent to retrieve information as needed.\n",
    "\n",
    "One of the most common uses is in **RAG (Retrieval-Augmented Generation) applications**, which **extend** the model's knowledge with updated data from:\n",
    "- **Websites**\n",
    "- **Structured data** (PDF, Word, CSV, Excel)\n",
    "- **Unstructured data** (HTML, TXT, digitized documents)\n",
    "\n",
    "**Example of RAG in action:**\n",
    "1. The user sends a question to the AI agent.\n",
    "2. The query is converted into **vector embeddings**.\n",
    "3. These embeddings are **compared** with those in the **vector database**.\n",
    "4. The most relevant content is retrieved and passed to the AI agent.\n",
    "5. The agent combines the information and provides a response to the user.\n",
    "\n",
    "---\n",
    "\n",
    "### **Conclusion**\n",
    "**Data Stores allow AI agents to access updated and accurate information without needing to retrain the model.**\n",
    "- They are ideal for applications **based on documents, knowledge bases, and structured data retrieval**.\n",
    "- **RAG + ReAct** enhances the decision-making process of AI agents, making them **smarter and contextually aware**.\n",
    "\n",
    "**Final result**: AI agents can **query a dynamic database** to obtain responses based on updated and relevant data, instead of relying on static knowledge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Improving Model Performance with Targeted Learning**\n",
    "\n",
    "To make the best use of an AI model, it is essential that it knows how to **choose the right tools** when generating output. However, many real-world situations require **additional knowledge** beyond what is contained in the training data.\n",
    "\n",
    "**Similar to cooking**, a chef may have basic knowledge, but to master a specific cuisine (e.g., Japanese), they need **targeted learning**.\n",
    "\n",
    "There are **three main approaches** to provide models with this specific knowledge:\n",
    "\n",
    "---\n",
    "\n",
    "### **1. In-Context Learning**\n",
    "The model **learns in real-time** by being provided with:\n",
    "- A **prompt** (like a recipe).\n",
    "- Some **tools** (ingredients).\n",
    "- **Few-shot examples** (examples of similar dishes).\n",
    "\n",
    "**Example (chef):**\n",
    "The chef receives a recipe with a few ingredients and uses their general knowledge to prepare the dish **on the fly**.\n",
    "\n",
    "**Example (AI):**\n",
    "An AI model uses the **ReAct framework**, which allows it to **reason and act dynamically** based on examples in the prompt.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Retrieval-Based In-Context Learning**\n",
    "The model **dynamically searches** for the most relevant information from an **external memory** (Data Store).\n",
    "- Retrieves useful data, tools, and examples to respond to the query.\n",
    "\n",
    "**Example (chef):**\n",
    "The chef has access to **a pantry full of ingredients and cookbooks**. They can choose what to use based on the customer's request, combining **experience and new information**.\n",
    "\n",
    "**Example (AI):**\n",
    "An AI agent with **RAG architecture** can query **databases, documents, and APIs** to retrieve updated information before generating a response.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Fine-Tuning Based Learning**\n",
    "The model is **pre-trained** on a larger dataset of specific examples **before receiving user queries**.\n",
    "- This method allows it to be **well-prepared** for specific tasks.\n",
    "\n",
    "**Example (chef):**\n",
    "The chef **goes back to school** to specialize in an exotic cuisine, so in the future, they can cook complex dishes without improvising.\n",
    "\n",
    "**Example (AI):**\n",
    "An AI model is **fine-tuned** on specific data (e.g., a medical dataset) to become **an expert in that domain**, improving its performance without needing to retrieve external data.\n",
    "\n",
    "---\n",
    "\n",
    "### **Conclusion**\n",
    "**Each method has pros and cons in terms of speed, cost, and latency.**\n",
    "By combining **In-Context Learning, Retrieval-Based Learning, and Fine-Tuning**, we can achieve AI agents that are more **adaptable and accurate**, capable of using the **best of each strategy**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **ðŸ“Œ Summary: Fundamentals and Future of AI Agents**\n",
    "\n",
    "This **whitepaper** explored the **fundamental concepts** of generative AI agents, their **structures**, and the most effective ways to implement them through **cognitive architectures**.\n",
    "\n",
    "---\n",
    "\n",
    "### **1. AI Agents Enhance Language Models**\n",
    "**Agents extend the capabilities of language models** by using tools that allow them to:\n",
    "   - **Access real-time information**.\n",
    "   - **Suggest and plan actions in the real world**.\n",
    "   - **Perform complex tasks autonomously**.\n",
    "\n",
    "An agent can use **one or more language models** to:\n",
    "   - **Manage complex states** (logical transitions between actions).\n",
    "   - **Use external tools to solve problems** that a language model alone could not address.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. The Orchestration Layer is the Core of the AI Agent**\n",
    "The **orchestration layer** is a **cognitive structure** that guides the agent in:\n",
    "   - **Reasoning**\n",
    "   - **Planning**\n",
    "   - **Decision-making**\n",
    "   - **Generating responses based on logic and data**\n",
    "\n",
    "**Reasoning techniques** include:\n",
    "   - **ReAct** (Reason + Act) â†’ To improve responses and reduce errors.\n",
    "   - **Chain-of-Thought (CoT)** â†’ To break down thinking into logical steps.\n",
    "   - **Tree-of-Thought (ToT)** â†’ To explore multiple solution paths.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Tools Connect Agents to the Real World**\n",
    "**AI agents use tools** to interact with external systems and **access up-to-date data**.\n",
    "\n",
    "**Types of tools:**\n",
    "- **Extensions** â†’ Connect agents to **external APIs** to obtain real-time data.\n",
    "- **Functions** â†’ Allow agents to **generate parameters** to execute **client-side**.\n",
    "- **Data Stores** â†’ Provide access to **structured and unstructured data**, enabling data-driven applications.\n",
    "\n",
    "---\n",
    "\n",
    "### **4. The Future of AI Agents**\n",
    "The field of AI agents is **constantly evolving** and the potential is still **unexplored**.\n",
    "\n",
    "**Future developments will include:**\n",
    "- **Improved tools and reasoning capabilities** â†’ Agents will become increasingly accurate and effective.\n",
    "- **Chaining of specialized agents** â†’ Creation of **networks of agents**, each expert in a specific domain.\n",
    "- **Advanced applications in various sectors** â†’ Business, healthcare, industrial automation, and more.\n",
    "\n",
    "---\n",
    "\n",
    "### **Conclusion**\n",
    "Creating **complex AI agents requires an iterative process** of **continuous experimentation and optimization**.\n",
    "**There is no perfect agent**, as each architecture is generative and depends on specific needs.\n",
    "By combining **language models, external tools, and orchestration strategies**, we can build **AI applications capable of generating real-world value**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Endnotes**\n",
    "\n",
    "1. **Shafran, I., Cao, Y. et al., 2022**  \n",
    "   *ReAct: Synergizing Reasoning and Acting in Language Models*.  \n",
    "   Available at: [https://arxiv.org/abs/2210.03629](https://arxiv.org/abs/2210.03629)\n",
    "\n",
    "2. **Wei, J., Wang, X. et al., 2023**  \n",
    "   *Chain-of-Thought Prompting Elicits Reasoning in Large Language Models*.  \n",
    "   Available at: [https://arxiv.org/pdf/2201.11903.pdf](https://arxiv.org/pdf/2201.11903.pdf)\n",
    "\n",
    "3. **Wang, X. et al., 2022**  \n",
    "   *Self-Consistency Improves Chain of Thought Reasoning in Language Models*.  \n",
    "   Available at: [https://arxiv.org/abs/2203.11171](https://arxiv.org/abs/2203.11171)\n",
    "\n",
    "4. **Diao, S. et al., 2023**  \n",
    "   *Active Prompting with Chain-of-Thought for Large Language Models*.  \n",
    "   Available at: [https://arxiv.org/pdf/2302.12246.pdf](https://arxiv.org/pdf/2302.12246.pdf)\n",
    "\n",
    "5. **Zhang, H. et al., 2023**  \n",
    "   *Multimodal Chain-of-Thought Reasoning in Language Models*.  \n",
    "   Available at: [https://arxiv.org/abs/2302.00923](https://arxiv.org/abs/2302.00923)\n",
    "\n",
    "6. **Yao, S. et al., 2023**  \n",
    "   *Tree of Thoughts: Deliberate Problem Solving with Large Language Models*.  \n",
    "   Available at: [https://arxiv.org/abs/2305.10601](https://arxiv.org/abs/2305.10601)\n",
    "\n",
    "7. **Long, X., 2023**  \n",
    "   *Large Language Model Guided Tree-of-Thought*.  \n",
    "   Available at: [https://arxiv.org/abs/2305.08291](https://arxiv.org/abs/2305.08291)\n",
    "\n",
    "8. **Google**  \n",
    "   *Google Gemini Application*.  \n",
    "   Available at: [http://gemini.google.com](http://gemini.google.com)\n",
    "\n",
    "9. **Swagger**  \n",
    "   *OpenAPI Specification*.  \n",
    "   Available at: [https://swagger.io/specification/](https://swagger.io/specification/)\n",
    "\n",
    "10. **Xie, M., 2022**  \n",
    "    *How does in-context learning work? A framework for understanding the differences from traditional supervised learning*.  \n",
    "    Available at: [https://ai.stanford.edu/blog/understanding-incontext/](https://ai.stanford.edu/blog/understanding-incontext/)\n",
    "\n",
    "11. **Google Research**  \n",
    "    *ScaNN (Scalable Nearest Neighbors)*.  \n",
    "    Available at: [https://github.com/google-research/google-research/tree/master/scann](https://github.com/google-research/google-research/tree/master/scann)\n",
    "\n",
    "12. **LangChain**  \n",
    "    *LangChain Documentation*.  \n",
    "    Available at: [https://python.langchain.com/v0.2/docs/introduction/](https://python.langchain.com/v0.2/docs/introduction/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Glossary of AI Agent Terminology**\n",
    "\n",
    "### **A**\n",
    "- **Agent**: A system that extends the capabilities of a language model by incorporating reasoning, tool usage, and real-world actions.\n",
    "- **Agent Chaining**: A method where multiple specialized agents collaborate, each handling a specific domain or task.\n",
    "- **Agent Orchestration**: The framework that manages an agentâ€™s reasoning, planning, and decision-making process.\n",
    "\n",
    "### **C**\n",
    "- **Chain-of-Thought (CoT)**: A reasoning technique where a model breaks down a problem into intermediate steps to improve logical inference.\n",
    "- **Client-Side Execution**: When API calls and logic are handled by the application using the AI agent, rather than the agent itself.\n",
    "\n",
    "### **D**\n",
    "- **Data Stores**: Storage systems that provide structured or unstructured data to an agent, allowing real-time access to updated knowledge.\n",
    "- **Decision-Making**: The process through which an AI agent determines the next action based on reasoning and available information.\n",
    "\n",
    "### **E**\n",
    "- **Embedding Model**: A machine learning model that converts text or other data into a numerical vector representation for efficient searching and retrieval.\n",
    "- **Extensions**: Tools that connect agents to external APIs, enabling them to retrieve real-time information or execute API calls.\n",
    "\n",
    "### **F**\n",
    "- **Fine-Tuning**: The process of training a language model on additional specific data to enhance its performance in a particular domain.\n",
    "- **Function Calling**: A method where an AI model generates parameters for a function, but the execution occurs outside the model, typically on a client-side system.\n",
    "\n",
    "### **H**\n",
    "- **Human-in-the-Loop (HITL)**: A method where humans supervise, validate, or intervene in the decision-making process of an AI model.\n",
    "\n",
    "### **I**\n",
    "- **In-Context Learning (ICL)**: A technique where a model learns how to perform a task dynamically by being provided with examples at inference time.\n",
    "\n",
    "### **L**\n",
    "- **Language Model (LM)**: An AI system trained to process and generate text based on vast amounts of training data.\n",
    "- **LangChain**: A framework for building AI-powered applications by linking language models with external tools and logic.\n",
    "- **LangGraph**: A library used to create structured agent workflows and reasoning paths.\n",
    "\n",
    "### **M**\n",
    "- **Middleware**: A software layer that connects different applications, such as AI agents and databases, allowing seamless data transfer and processing.\n",
    "- **Multi-Modal Chain-of-Thought**: A CoT reasoning approach that incorporates various data types, such as text and images, to improve decision-making.\n",
    "\n",
    "### **O**\n",
    "- **Orchestration Layer**: The central component of an agent that organizes its reasoning and tool usage, ensuring efficient task execution.\n",
    "\n",
    "### **P**\n",
    "- **Prompt Engineering**: The process of designing and structuring inputs to guide an AI model in generating better responses.\n",
    "\n",
    "### **R**\n",
    "- **ReAct (Reasoning + Acting)**: A framework where an AI agent first reasons about a task before taking an action, enhancing decision-making and reducing errors.\n",
    "- **Retrieval-Augmented Generation (RAG)**: A technique where an AI model retrieves external information before generating a response.\n",
    "- **Reasoning Frameworks**: Structured approaches like ReAct, CoT, and Tree-of-Thoughts that guide an AI's logical processing.\n",
    "- **Reinforcement Learning with Human Feedback (RLHF)**: A training method where human preferences help fine-tune an AI modelâ€™s responses.\n",
    "\n",
    "### **S**\n",
    "- **Self-Consistency**: A method that improves reasoning in AI models by generating multiple solutions and selecting the most consistent one.\n",
    "- **Stop Sequence**: A specific token or character that prevents an AI model from continuing to generate unnecessary text.\n",
    "\n",
    "### **T**\n",
    "- **Tool**: A function, API, or external system that an AI agent can use to enhance its capabilities and interact with real-world data.\n",
    "- **Tree-of-Thought (ToT)**: A structured reasoning method where an AI explores multiple possible reasoning paths before making a decision.\n",
    "\n",
    "### **U**\n",
    "- **Unstructured Data**: Information that is not stored in a predefined format, such as text files, images, or PDFs.\n",
    "\n",
    "### **V**\n",
    "- **Vector Database**: A database that stores information as high-dimensional vectors, enabling efficient similarity searches.\n",
    "\n",
    "### **W**\n",
    "- **Workflow Automation**: The use of AI agents to manage and streamline repetitive business processes.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
